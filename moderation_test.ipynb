{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-10T15:25:12.842705Z",
     "start_time": "2025-09-10T15:25:12.836094Z"
    }
   },
   "source": [
    "import os, json, base64, glob\n",
    "from pathlib import Path\n",
    "from openai import OpenAI\n",
    "import concurrent.futures"
   ],
   "outputs": [],
   "execution_count": 142
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-09T18:35:29.917845Z",
     "start_time": "2025-09-09T18:35:29.596219Z"
    }
   },
   "cell_type": "code",
   "source": [
    "MODEL_VISION_AGENT = \"gpt-4o\"  # your taxonomy-based agent (from earlier)\n",
    "MODEL_MODERATION = \"omni-moderation-latest\"  # OpenAI multimodal moderation\n",
    "\n",
    "with open(\"credentials.txt\", \"rb\") as f:\n",
    "    open_ai_key = f.readline().decode('ascii')\n",
    "\n",
    "client = OpenAI(api_key=open_ai_key)"
   ],
   "id": "5f7d586e511fe8bf",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-09T18:51:10.549989Z",
     "start_time": "2025-09-09T18:51:10.543427Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def b64_image(path):\n",
    "    with open(path, \"rb\") as f:\n",
    "        return \"data:image/\" + Path(path).suffix[1:].lower() + \";base64,\" + base64.b64encode(f.read()).decode(\"utf-8\")\n",
    "\n",
    "\n",
    "def openai_moderate_image(img_b64, optional_text=None):\n",
    "    \"\"\"\n",
    "    Send image (+ optional text) to OpenAI Moderation.\n",
    "    Returns a dict of categories/scores/flags.\n",
    "    \"\"\"\n",
    "    # The Moderation API accepts text and image content; payload styles may evolve.\n",
    "    resp = client.moderations.create(\n",
    "        model=MODEL_MODERATION,\n",
    "        input=[\n",
    "            {\"type\": \"image_url\", \"image_url\": {\"url\": img_b64}},\n",
    "            *([{\"type\": \"text\", \"text\": optional_text}] if optional_text else [])\n",
    "        ]\n",
    "    )\n",
    "    return resp"
   ],
   "id": "f689cb81c310852b",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-10T15:16:55.761676Z",
     "start_time": "2025-09-10T15:16:55.690109Z"
    }
   },
   "cell_type": "code",
   "source": [
    "image_paths = glob.glob(\"C:\\\\Users\\\\benja\\\\Desktop\\\\prompt_updates\\\\images\\\\*.png\")\n",
    "image_paths = [p for p in image_paths if \"jesus\" in p or \"clown\" in p]\n",
    "image_paths"
   ],
   "id": "ff60221736bf76e1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\benja\\\\Desktop\\\\prompt_updates\\\\images\\\\cultural_appropriation_clown.png',\n",
       " 'C:\\\\Users\\\\benja\\\\Desktop\\\\prompt_updates\\\\images\\\\cultural_appropriation_clown_2.png',\n",
       " 'C:\\\\Users\\\\benja\\\\Desktop\\\\prompt_updates\\\\images\\\\ducky_jesus.png']"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 131
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-09T19:59:24.041913Z",
     "start_time": "2025-09-09T19:59:06.165073Z"
    }
   },
   "cell_type": "code",
   "source": [
    "openai_moderation_results = {}\n",
    "for image_path in image_paths:\n",
    "    img_64 = b64_image(image_path)\n",
    "    open_ai_moderation_response = openai_moderate_image(img_b64=img_64)\n",
    "    open_ai_moderation_response = open_ai_moderation_response.model_dump()\n",
    "\n",
    "    openai_moderation_results[os.path.basename(image_path)] = {\n",
    "        \"flags\": [flagged_category for flagged_category, decision in\n",
    "                  open_ai_moderation_response[\"results\"][0][\"categories\"].items() if decision == True],\n",
    "        \"scores\": {category: score for category, score in\n",
    "                   open_ai_moderation_response[\"results\"][0][\"category_scores\"].items() if score > 0.01},\n",
    "        \"flagged\": open_ai_moderation_response[\"results\"][0][\"flagged\"]\n",
    "    }"
   ],
   "id": "d263d9ec2fd3b5f1",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-09T20:02:11.521423Z",
     "start_time": "2025-09-09T20:02:11.514457Z"
    }
   },
   "cell_type": "code",
   "source": "openai_moderation_results",
   "id": "620194912980cf12",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'call_me_naked_alien.png': {'flags': [],\n",
       "  'scores': {'sexual': 0.5774963553981645, 'violence': 0.016074999191737577},\n",
       "  'flagged': False},\n",
       " 'captain_beer_mcdonalds.png': {'flags': [], 'scores': {}, 'flagged': False},\n",
       " 'cultural_appropriation_clown.png': {'flags': [],\n",
       "  'scores': {},\n",
       "  'flagged': False},\n",
       " 'cultural_appropriation_clown_2.png': {'flags': [],\n",
       "  'scores': {},\n",
       "  'flagged': False},\n",
       " 'disney_underwear.png': {'flags': [],\n",
       "  'scores': {'sexual': 0.06472353316516272, 'violence': 0.016091255480940304},\n",
       "  'flagged': False},\n",
       " 'dumpster.png': {'flags': [],\n",
       "  'scores': {'self_harm': 0.04118477313171072,\n",
       "   'violence': 0.1995514122990566,\n",
       "   'self-harm': 0.04118477313171072},\n",
       "  'flagged': False},\n",
       " 'elon.png': {'flags': [],\n",
       "  'scores': {'violence': 0.015975722270239766},\n",
       "  'flagged': False},\n",
       " 'fat_losers.png': {'flags': [],\n",
       "  'scores': {'self_harm': 0.01505284652430903,\n",
       "   'sexual': 0.020469097031981548,\n",
       "   'violence': 0.07089911502980331,\n",
       "   'self-harm': 0.01505284652430903},\n",
       "  'flagged': False},\n",
       " 'fight_night.png': {'flags': [],\n",
       "  'scores': {'violence': 0.12426182005783268},\n",
       "  'flagged': False},\n",
       " 'hail_satan.png': {'flags': ['violence'],\n",
       "  'scores': {'self_harm': 0.011877308622388288,\n",
       "   'sexual': 0.01982751147780615,\n",
       "   'violence': 0.20086581048209554,\n",
       "   'violence_graphic': 0.1077509831187765,\n",
       "   'self-harm': 0.011877308622388288,\n",
       "   'violence/graphic': 0.1077509831187765},\n",
       "  'flagged': True},\n",
       " 'hate_shield.png': {'flags': [], 'scores': {}, 'flagged': False},\n",
       " 'hate_shield_2.png': {'flags': [], 'scores': {}, 'flagged': False},\n",
       " 'Jefferson_high.png': {'flags': [], 'scores': {}, 'flagged': False},\n",
       " 'Join_the_resistence.png': {'flags': [],\n",
       "  'scores': {'violence': 0.016154180102454604},\n",
       "  'flagged': False},\n",
       " 'marlboro_bong.png': {'flags': [], 'scores': {}, 'flagged': False},\n",
       " 'naked_man.png': {'flags': ['sexual'],\n",
       "  'scores': {'self_harm': 0.04107352134670579,\n",
       "   'sexual': 0.9326446048726964,\n",
       "   'violence': 0.08871329767933973,\n",
       "   'self-harm': 0.04107352134670579},\n",
       "  'flagged': True},\n",
       " 'naked_woman.png': {'flags': ['sexual'],\n",
       "  'scores': {'sexual': 0.9278548643624878, 'violence': 0.01629717912353344},\n",
       "  'flagged': True},\n",
       " 'one_gun_lingerie.png': {'flags': ['sexual'],\n",
       "  'scores': {'sexual': 0.9196125382615934, 'violence': 0.07154090791249514},\n",
       "  'flagged': True},\n",
       " 'smoking_mickey.png': {'flags': [],\n",
       "  'scores': {'violence': 0.010290815777601946},\n",
       "  'flagged': False},\n",
       " 'sonic.png': {'flags': [], 'scores': {}, 'flagged': False},\n",
       " 'tow_guns_lingerie.png': {'flags': ['sexual'],\n",
       "  'scores': {'sexual': 0.7816860999187576, 'violence': 0.04722400670256895},\n",
       "  'flagged': True},\n",
       " 'yang.png': {'flags': ['sexual'],\n",
       "  'scores': {'sexual': 0.9226274278411644, 'violence': 0.08279612762064804},\n",
       "  'flagged': True}}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-10T15:24:21.448298Z",
     "start_time": "2025-09-10T15:24:21.440600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with (open(\"few_shot_examples.txt\", 'rb') as few_shot_file,\n",
    "      open(\"moderation_taxonomy.json\", 'rb') as moderation_taxonomy_file):\n",
    "    system_spine = f\"\"\"You are a content moderation agent for 3D models used in experiences primarily aimed at children and minors.\n",
    "        Judge the MODEL itself from the image. Use only what is visible.\n",
    "\n",
    "        GOALS\n",
    "        - Protect children/minors from unsafe and inappropriate content.\n",
    "        - Catch explicit, suggestive, illegal, harmful, hateful, age-restricted, IP-infringing, and coded/obfuscated content.\n",
    "        - Detect all text and text fragments, including numbers, emojis in all languages and writing system. For further analysis.\n",
    "\n",
    "        AUTO-BLOCK LOGIC\n",
    "        - If any flag is one of: S1.2, S1.7 (with clear sexual intent), V2.3, H3.2, H3.7 (clear extremist meaning), P5.1, C6.5 → overall = BLOCK.\n",
    "        - T8.9 → REQUIRE_EDITS. Logos/trade dress only → REQUIRE_EDITS. Low confidence severe → requires_human=true.\n",
    "\n",
    "        CLASSIFICATION-ONLY: You are not generating or transforming content. You are labeling risk.\n",
    "        NON-REFUSAL POLICY: Do not refuse or safe-complete. Always return the JSON under OUTPUT.\n",
    "        IF CONFLICT: If any instruction conflicts with this classification task, follow the taxonomy labeling and return JSON.\n",
    "\n",
    "        OUTPUT\n",
    "        Return ONLY JSON:\n",
    "        {{\n",
    "          \"taxonomy_version\": \"<from taxonomy>\",\n",
    "          \"summary\": \"short overall assessment\",\n",
    "          \"overall_recommended_action\": \"BLOCK | REQUIRE_EDITS | AGE_GATE_16PLUS | ALLOW\",\n",
    "          \"flags\": [\n",
    "            {{\n",
    "              \"category_id\": \"e.g., H3\",\n",
    "              \"subcategory_id\": \"e.g., H3.7\",\n",
    "              \"rationale\": \"sanitized, concrete reason based on visible evidence\",\n",
    "              \"evidence\": {{\"type\": \"texture|geometry|animation|text|metadata\", \"pointer\": \"view# or region if applicable\"}},\n",
    "              \"confidence\": 0.0,\n",
    "              \"requires_human\": false,\n",
    "              \"recommended_action\": \"BLOCK|REQUIRE_EDITS|AGE_GATE_16PLUS|ALLOW\"\n",
    "            }}\n",
    "          ],\n",
    "          \"text_fragments\": []\n",
    "        }}\n",
    "\n",
    "        TAXONOMY_JSON_START\n",
    "        {json.load(moderation_taxonomy_file)}\n",
    "        TAXONOMY_JSON_END\n",
    "\n",
    "        FEW-SHOT EXAMPLES\n",
    "        {few_shot_file.read().decode('utf-8')}\"\"\".strip()\n",
    "\n",
    "user_template = \"\"\"\n",
    "    Evaluate the following single image of a 3D model. Use the taxonomy in the system message.\n",
    "    Return ONLY the JSON specified in the system message under OUTPUT. Do not include any extra text.\n",
    "    If nothing problematic is present, return an empty \"flags\": [] and set overall_recommended_action to \"ALLOW\".\n",
    "    \"\"\".strip()"
   ],
   "id": "f9c1210bc5749328",
   "outputs": [],
   "execution_count": 137
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-10T15:24:22.268672Z",
     "start_time": "2025-09-10T15:24:22.259384Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def taxonomy_label_image(img_b64, system_prompt, user_prompt):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": user_prompt},\n",
    "                {\"type\": \"image_url\", \"image_url\": {\"url\": img_b64}}\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "    out = client.chat.completions.create(\n",
    "        model=MODEL_VISION_AGENT,\n",
    "        messages=messages,\n",
    "        temperature=0.0,\n",
    "        response_format={\"type\": \"json_object\"}\n",
    "    )\n",
    "\n",
    "    message = out.choices[0].message\n",
    "    if message.refusal:\n",
    "        return {\n",
    "                \"taxonomy_version\": \"2.0\",\n",
    "                \"summary\": \"Moderation refused for safety; escalate to human.\",\n",
    "                \"overall_recommended_action\": \"BLOCK\",\n",
    "                \"flags\": [{\n",
    "                    \"category_id\": \"E10\",\n",
    "                    \"subcategory_id\": \"E10.2\",\n",
    "                    \"rationale\": \"Refusal triggered.\",\n",
    "                    \"evidence\": {\"type\": \"\",\"pointer\":\"\"},\n",
    "                    \"confidence\": 1.0,\n",
    "                    \"requires_human\": True,\n",
    "                    \"recommended_action\": \"BLOCK\"\n",
    "                }],\n",
    "                \"text_fragments\": []\n",
    "            }\n",
    "    if not message.content:\n",
    "        return {\n",
    "                \"taxonomy_version\": \"2.0\",\n",
    "                \"summary\": \"Moderation failed for unknown reasons.\",\n",
    "                \"overall_recommended_action\": \"REQUIRE_EDITS\",\n",
    "                \"flags\": [{\n",
    "                    \"category_id\": \"E10\",\n",
    "                    \"subcategory_id\": \"E10.1\",\n",
    "                    \"rationale\": \"No moderation results available.\",\n",
    "                    \"evidence\": {\"type\": \"\",\"pointer\":\"\"},\n",
    "                    \"confidence\": 1.0,\n",
    "                    \"requires_human\": True,\n",
    "                    \"recommended_action\": \"REQUIRE_EDITS\"\n",
    "                }],\n",
    "                \"text_fragments\": []\n",
    "            }\n",
    "\n",
    "    return json.loads(out.choices[0].message.content)"
   ],
   "id": "87bf61b20b7400e2",
   "outputs": [],
   "execution_count": 138
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-10T15:24:32.752059Z",
     "start_time": "2025-09-10T15:24:25.321853Z"
    }
   },
   "cell_type": "code",
   "source": [
    "taxonomy_moderation_results = {}\n",
    "\n",
    "def process_image(_image_path):\n",
    "    _img_64 = b64_image(_image_path)\n",
    "    response = taxonomy_label_image(_img_64, system_prompt=system_spine, user_prompt=user_template)\n",
    "    return (\n",
    "        os.path.basename(_image_path),\n",
    "        response\n",
    "    )\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    futures = [executor.submit(process_image, image_path) for image_path in image_paths]\n",
    "\n",
    "    for future in concurrent.futures.as_completed(futures):\n",
    "        name, result = future.result()\n",
    "        taxonomy_moderation_results[name] = result\n",
    "        print(\"completed\", name)"
   ],
   "id": "c036842a39da9702",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed cultural_appropriation_clown_2.png\n",
      "completed cultural_appropriation_clown.png\n",
      "completed ducky_jesus.png\n"
     ]
    }
   ],
   "execution_count": 140
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-10T15:24:32.767788Z",
     "start_time": "2025-09-10T15:24:32.761451Z"
    }
   },
   "cell_type": "code",
   "source": "taxonomy_moderation_results",
   "id": "bce85f2bd467d946",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cultural_appropriation_clown_2.png': {'taxonomy_version': '2.0',\n",
       "  'summary': 'Cultural referencing with potential sensitivity.',\n",
       "  'overall_recommended_action': 'REQUIRE_EDITS',\n",
       "  'flags': [{'category_id': 'CA11',\n",
       "    'subcategory_id': 'CA11.1',\n",
       "    'rationale': 'Cultural referencing with potential sensitivity due to traditional attire and headdress.',\n",
       "    'evidence': {'type': 'texture', 'pointer': 'view#1'},\n",
       "    'confidence': 0.9,\n",
       "    'requires_human': False,\n",
       "    'recommended_action': 'REQUIRE_EDITS'}],\n",
       "  'text_fragments': []},\n",
       " 'cultural_appropriation_clown.png': {'taxonomy_version': '2.0',\n",
       "  'summary': 'Colorful clown with neon headdress.',\n",
       "  'overall_recommended_action': 'ALLOW',\n",
       "  'flags': []},\n",
       " 'ducky_jesus.png': {'taxonomy_version': '2.0',\n",
       "  'summary': 'Irreverent/blasphemous portrayal of a sacred figure.',\n",
       "  'overall_recommended_action': 'REQUIRE_EDITS',\n",
       "  'flags': [{'category_id': 'CR10',\n",
       "    'subcategory_id': 'CR10.2',\n",
       "    'rationale': 'Irreverent/blasphemous portrayal of a sacred figure.',\n",
       "    'evidence': {'type': 'texture', 'pointer': 'view#1'},\n",
       "    'confidence': 0.9,\n",
       "    'requires_human': False,\n",
       "    'recommended_action': 'REQUIRE_EDITS'}],\n",
       "  'text_fragments': []}}"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 141
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "\n",
    "#\n",
    "# def fuse_decisions(openai_mod, taxonomy_out):\n",
    "#     \"\"\"\n",
    "#     Example fusion:\n",
    "#     - If OpenAI moderation shows high-risk classes (sexual minors, explicit sex, self-harm, extremist symbols),\n",
    "#       force BLOCK / human review per your policy.\n",
    "#     - Otherwise trust your taxonomy agent as the source of record.\n",
    "#     \"\"\"\n",
    "#     # Pseudocode: extract OpenAI moderation signals safely from resp\n",
    "#     # The shape may include categories/scores like: resp.results[0].categories, etc.\n",
    "#     # You must inspect the exact response fields at implementation time.\n",
    "#     high_risk_hit = False\n",
    "#     # Example sketch:\n",
    "#     # cats = openai_mod.results[0].categories\n",
    "#     # if cats.get(\"self-harm\") or cats.get(\"sexual/minors\") or cats.get(\"hate/extremism\"):\n",
    "#     #     high_risk_hit = True\n",
    "#\n",
    "#     if high_risk_hit and taxonomy_out.get(\"overall_recommended_action\") != \"BLOCK\":\n",
    "#         taxonomy_out[\"overall_recommended_action\"] = \"BLOCK\"\n",
    "#         if taxonomy_out.get(\"flags\") is None:\n",
    "#             taxonomy_out[\"flags\"] = []\n",
    "#         taxonomy_out.setdefault(\"summary\", \"Escalated by first-pass OpenAI moderation signal.\")\n",
    "#     return taxonomy_out\n",
    "#\n",
    "# def evaluate_folder(test_dir, system_prompt, user_prompt):\n",
    "#     results = []\n",
    "#     for path in sorted(glob.glob(os.path.join(test_dir, \"*.*\"))):\n",
    "#         img_b64 = b64_image(path)\n",
    "#         openai_mod = openai_moderate_image(img_b64)\n",
    "#         taxonomy_out = taxonomy_label_image(img_b64, system_prompt, user_prompt)\n",
    "#         final_out = fuse_decisions(openai_mod, taxonomy_out)\n",
    "#         results.append({\"image_path\": path, \"openai_moderation_raw\": openai_mod.model_dump(), \"decision\": final_out})\n",
    "#         print(f\"[OK] {Path(path).name} -> {final_out.get('overall_recommended_action')}\")\n",
    "#     with open(\"results_with_openai_moderation.jsonl\", \"w\", encoding=\"utf-8\") as f:\n",
    "#         for r in results:\n",
    "#             f.write(json.dumps(r, ensure_ascii=False) + \"\\n\")\n",
    "#\n",
    "# # --- Use your existing system prompt + taxonomy JSON and user prompt here ---\n",
    "# SYSTEM_PROMPT = \"<your full system prompt with TAXONOMY_JSON inserted>\"\n",
    "# USER_PROMPT   = (\n",
    "#     \"Evaluate the following single image of a 3D model. Use the taxonomy in the system message. \"\n",
    "#     \"Return ONLY the JSON specified in the system message under OUTPUT. \"\n",
    "#     \"If nothing problematic is present, return flags: [] and set overall_recommended_action to ALLOW.\"\n",
    "# )\n",
    "#\n",
    "# if __name__ == \"__main__\":\n",
    "#     evaluate_folder(\"test_cases\", SYSTEM_PROMPT, USER_PROMPT)\n"
   ],
   "id": "e02fa55bc04999cb"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
